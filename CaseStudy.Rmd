---
title: "A Case study in Silent Data Corruption in an RNA-Seq Experiment"
subtitle: "A bad counts file, an incorrect error message, and counter-intuitive R behavior converge to create a plausible scenario for silent results corruption"
author: "Thadryan J. Sweeney"
output:
  pdf_document: default
  word_document: default
  html_document: default
---

This report describes a series of small issues that can converge such that a `DESeq2` analysis runs from start to finish and raises no errors, but silently corrupts and invalidates the data. The results may or may not seem feasible enough to alert the analyst upon initial inspection. I observed it in practice and detected it using DESeq2's quality control functions. It seemed all-too-plausible that the situation could arise in other projects, so I've documented it for study. If nothing else, it can serve as a reminder of some easily forgotten but counter-intuitive and consequential default behavior of R.

## TL;DNR

If a stray character exists in a file being used as a counts matrix, R will read the affected columns of the dataset as `factor`s instead of `integer`s or `numeric`s (in my case, a header row was duplicated several thousand rows into the file, affecting them all).

Though we're passing `factor`s, `DESeq2` will raise an error stating that the user has passed `character`s and should be passing `numeric`s.

A `character` can be safely cast as an `integer` or `numeric`, but a `factor` cannot; R will silently convert to a ranked sequence, completely invalidating the data (for example, the sequence 1, 100, 1000 is changed to 1, 2, 3).

This new, incorrect dataset will run without errors, but is basically unrelated to what the user intends to analyze. 

*Note:* a bug report has been filed on Bioconductor and the error message updated. Click [here](https://support.bioconductor.org/p/130310/#130371) for the link.

## Steps to Re-create

We will re-create the issues using the sample analysis from the `DESeq2` vignette. 

### Obtain a counts file

This snippet simply loads a counts file in accordance with the documentation of DESeq2.

```{R, message = FALSE}

library(DESeq2)    # go-to DE analysis package
library(pasilla)   # sample data used in tutorial
library(tidyverse) # data manipulation 

# get the counts information from the pasilla package
pasCts <- system.file("extdata", "pasilla_gene_counts.tsv",
                      package = "pasilla", mustWork = TRUE)

# load the sample annotation file from the pasilla package
pasAnno <- system.file("extdata", "pasilla_sample_annotation.csv",
                       package = "pasilla", mustWork = TRUE)

# create a matrix of counts
cts <- as.matrix(read.csv(pasCts, sep = "\t", row.names = "gene_id"))

# read in the sample data.
coldata <- read.csv(pasAnno, row.names = 1)

# select the desired features (just following the tutorial)
coldata <- coldata[, c("condition","type")]

# clean/standardize the rownames
rownames(coldata) <- sub("fb", "", rownames(coldata))

# sort/reorder the columns to match samples
cts <- cts[, rownames(coldata)]
```

### Introduce a character

I found the issue after reading in a bad counts matrix file that was given to me. Somewhere in pre-processing a header of some kind had gotten duplicated and nestled a few thousand rows into the counts file. It looked something like this:
    
    sampleName sampleName sampleName sampleName sampleName sampleName sampleName
  
Perhaps tables had been stacked on top of one another to make the counts file and there was an off-by-one error, I don't know, but it is an easy error to imagine making in Bioinformatics and data-related computing in general. It can be reproduced like this:

```{R}

ctsBad <- cts

# add a character row
ctsBad[8600, ] <- c("here", "there", "and", "everywhere", "yeah", "whoo!", "oops!")

# inspect
ctsBad[8597:8602, ]

# write to a file
write.csv(ctsBad, "badCounts.csv")
```

When we read the data from a file, the well-known-but-still-menacing factor default issues comes in to play. However, `DESeq2` appears to misdiagnose the types. To see how, we first read in the file with the bad row. 

```{R}

ctsBadFile <- read.delim("badCounts.csv", sep = ",")

# we're no longer getting integers
sapply(ctsBadFile, class)

ctsBadFile[8597:8602, ]
```

This behavior is consistently tricky, but well-documented (and thankfully, changing). It becomes a more complex issue when mixed with a misleading error message and some more counter-intuitive bahavior.

### Call DESeqDataSetFromMatrix()

We can now observe that passing `factor`s results in being warned we are passing `character`s.

```{R, tidy=TRUE, tidy.opts=list(width.cutoff=60)}

# make the input the corrected sized matrix
ctsBadFile$X <- NULL

# demonstrate that we're passing factors
sapply(ctsBadFile, class)

error <- tryCatch(
  {
    # try to use the bad one
    dds <- DESeqDataSetFromMatrix(countData = ctsBadFile,
                                  colData = coldata, design = ~ condition)
  },
  # "upon error 'e', use this function to show a message of 'e'"
  error = function(e) { return(e)}
)

# show the error messagge (just splitting it because it is long)
errorMessage <- unlist(str_split(error, ":"))

cat("\n", errorMessage[2], errorMessage[3])
```

We see that `DESeq2` informs us we're passing `character`s, though we have actually passed `factor`s (a detailed possible explanation of why this happens is presented in the analysis included with the bug report. Click [here](https://drive.google.com/file/d/1Trr0lbMklHpPTWuQdrA4zujd7q_30t4m/view)) to view it. The implied fix is to convert the dataset to `numeric`s or `integer`s. However, either of those steps result in silent data corruption because `factor`s cannot be coerced to `integer`s or `numeric`s safely even though `character`s can. The problem is demonstrated below (an atomic, reproducible example of the related behavior is included at the bottom of the report).

```{R}

# apply the fix insinutated by the error message
ctsBadFileAsInt <- ctsBadFile %>%
  mutate_all(as.integer)

ctsBadFileAsNumeric <- ctsBadFile %>%
  mutate_all(as.numeric)
```

We can then see the dataset before and after coercion. Before:

```{R}

# inspect the original and factor versions
cts %>% head()
ctsBadFile %>% head()
```

After: 

```{R}

ctsBadFileAsInt %>% head()
ctsBadFileAsNumeric %>% head()
```

We can get some intuition for the shift with a quick, if hacky, plot:

```{R}

bin <- 1000

# the original dataset
ggplot(gather(data.frame(cts)), aes(value)) + 
    geom_histogram(bins = bin) + 
    facet_wrap(~key) +
    ylim(0, 100) +
    ggtitle("Before Coercion")

# the corrupted one
ggplot(gather(data.frame(ctsBadFileAsInt)), aes(value)) + 
    geom_histogram(bins = bin) + 
    facet_wrap(~key) +
    ylim(0, 100) +
    ggtitle("After Coercion")

```

Either of these corrupted datasets will run without error:

````{R}

ddsBadInt <- DESeqDataSetFromMatrix(countData = ctsBadFileAsInt,
                                    colData = coldata, design = ~ condition)
```

This warns that the `numeric`s are being converted to `integer` (a safe operation).

```{R}

ddsBadNumeric <- DESeqDataSetFromMatrix(countData = ctsBadFileAsNumeric,
                                        colData = coldata, design = ~ condition)
```

## Prevention

I have taken to including a line like this in my read-in scripts:

    stopifnot(is.null(names(Filter(is.factor, ctsBadFile))))

```{R}

tryCatch(
  {
    stopifnot(is.null(names(Filter(is.factor, ctsBadFile))))
  },
  error = function(m){ print(m) }
)
```

## Comments

This is not a criticism of `DESeq2`. This is not to say that the analyst is not responsible for understanding their types. It is merely an effort to identify a potential source of error and reduce it. It's not hard to imagine a stray character row finding it's way into a counts file, and a hurried analyst not noticing and following a misleading error. I propose that it is especially important to be vigilant about type-related bugs given that many R users are investigators from other disciples who may not have experience programming, and even if they do, are likely to have it in a language where type-awareness is not necessarily required or promoted (as in R itself).

I am aware that the eternal confounder `stringsAsFactors=TRUE` was addressed in the newest release of R, which is progress. It makes this scenario markedly less likely, though not impossible. The other issues addressed are still worth refreshing on, especially the silent coercion issue. 

## Atomic Example of Factor Behavior

An atomic example of this troubling behavior may illuminate the issue. `character`s can be safely coerced to `integer`s, but `factor`s cannot. Moreover, they fail silently and return invalid results. We demonstrate below for the sake of completeness:

```{R}

# a vector of integers
x <- c("1", "10", "100", "1000")

as.integer(x)
```

When you do that to a vector of `factor`s however, you silently receive a counter-intuitive result:

```{R}

# the same, as a factor
x <- factor(c("1", "10", "100", "1000"))

as.integer(x)
```

## Session Info

```{R}

sessionInfo()
```